---
title: 'Applied Machine Learning - Observing Data'
author: 'Samuel Louissaint'
date: '2022-03-03'
slug: observing-data
categories:
  - R
  - Applied Machine Learning
tags:
  - dashboard
  - data exploration
  - machine learning
  - shiny
  - visualization
subtitle: ''
summary: ''
authors: []
lastmod: '2022-03-03T00:25:43-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


#### This is the first entry in a series where I will be using R to replicate a graduate-level applied machine learning course that is purely in Python.
  
The goal of the first class period was to introduce some of the data manipulation packages in Python to students. As such, most of the code here will be pretty simple to replicate since data manipulation is the bread-and-butter of R. However, there is a bit of interactivity in the final section that I am looking forward to work on. All of the code chunks are included so feel free to take your time and understand what each piece is doing.

## Preparing Data

For this lab, we used two datasets from the [UCI Data Repository](https://archive.ics.uci.edu/ml/index.php):  
[Forest Fires Data](https://archive.ics.uci.edu/ml/index.php)  
[Auto MPG Data](https://archive.ics.uci.edu/ml/datasets/Auto+MPG)  
First we need to load in the packages we're going to use. In Python we used Numpy and Pandas for data handling, and Matplotlib for visuzalization. The R equivalents are tidyr, dplyr, and ggplot2, though getting familiar with more of the tidyverse library doesn't hurt. gridExtra will let us arrange multiple grids on one page.
```{r}
library(tidyverse)
library(readr)
library(gridExtra)
library(grid)
library(shiny)
```

After downloading the data and placing it in your current working directory, you can load it like so:
```{r}
ff_data <- read_csv('forestfires.csv', show_col_types = F)
ff_data # Let's take a look at what we've loaded.
```

In Python, we completed this first task using 'np.loadtxt()' which created an intentional error that required students to convert the month and day columns to numeric values. For the sake of being thorough, one way (of many) to do this is in the chunk below.  
I'll be demonstrating only the last 20 observations when printing dataframes only due to the length of the data.
```{r}
ff_data_num <- as.data.frame(ff_data %>%
  mutate(month = case_when(month =='jan' ~ 1,
                           month =='feb' ~ 2,
                           month =='mar' ~ 3,
                           month =='apr' ~ 4,
                           month =='may' ~ 5,
                           month =='jun' ~ 6,
                           month =='jul' ~ 7,
                           month =='aug' ~ 8,
                           month =='sep' ~ 9,
                           month =='oct' ~ 10,
                           month =='nov' ~ 11,
                           month =='dec' ~ 12),
         day = case_when(day =='mon' ~ 1,
                         day =='tue' ~ 2,
                         day =='wed' ~ 3,
                         day =='thu' ~ 4,
                         day =='fri' ~ 5,
                         day =='sat' ~ 6,
                         day =='sun' ~ 7)))
tail(ff_data_num, 20) # Once again, let's see what we did.
```
The case_when function takes a logical statement and performs an action in cases where the result is TRUE. In that way it's very similar to if-else functions though I prefer case_when in these situations.

Next we'll use a few functions to learn some details about our data.
```{r}
head(ff_data_num, 5) # returns first 5 rows
colnames(ff_data_num) # returns the column names
dim(ff_data_num) # returns the number of rows and columns in the data
length(which(is.na(ff_data_num))) # returns number of NA values in the data
```

Splicing and indexing dataframes is a useful way to access pieces of your data. This can be done within and outside of tidyverse relatively easily.
```{r}
tail(ff_data_num['area'], 20)
# these indexing methods following the dataframe name produce the same output:
# [,'area'], [,13], [, -1:-12]

tail(ff_data_num %>%
  select(area), 20)
```

Unlike pandas.describe(), the summary function used in R doesn't include the count or standard deviation for numeric columns.
```{r}
summary(ff_data_num)
```

## Visualizing Data
The grammar of graphics package known as ggplot2 is the primary graphical visualization package in R. We'll flex its muscles just a bit to demonstrate a simple line chart and histogram. Notice there are a large number of forest fires with an area of 0. This is the reason I've opted to display the last twenty observations instead of the first twenty. This is also something to keep in mind for the Shiny app at the end.
```{r, warning = F}
ggplot(ff_data_num) +
  geom_line(aes(1:length(ff_data_num$area), area, color = 'coral2')) +
  labs(x= 'Row Number') +
  theme_classic()
ggplot(ff_data_num, mapping = aes(area, fill = 'coral2')) +
  geom_histogram(binwidth = 100) +
  theme_classic()
```

## Putting it all together
#### Splitting data into features and targets
In later posts, we'll want to predict a given feature which we refer to as our target. The remaining features will act as our input data to predict the target. Thus it can be useful to split our input features and target into two different variables.
```{r}
t <- ff_data_num %>% select(area)
head(t)
X <- ff_data_num %>% select(-area)
head(X)
```

Generating subplots in R is just a bit clunkier than it is in Python as you need to enter each plot as a graphical object into grid.arrange. Because of that, I made each graph individually rather than in a loop.
```{r, fig.width= 12, fig.height=9, warning=FALSE}
p1 <- qplot(1:length(X), X, data = X, geom = "line")
p2 <- qplot(1:length(Y), Y, data = X, geom = "line")
p3 <- qplot(1:length(month), month, data = X, geom = "line")
p4 <- qplot(1:length(day), day, data = X, geom = "line")
p5 <- qplot(1:length(FFMC), FFMC, data = X, geom = "line")
p6 <- qplot(1:length(DMC), DMC, data = X, geom = "line")
p7 <- qplot(1:length(DC), DC, data = X, geom = "line")
p8 <- qplot(1:length(ISI), ISI, data = X, geom = "line")
p9 <- qplot(1:length(temp), temp, data = X, geom = "line")
p10 <- qplot(1:length(RH), RH, data = X, geom = "line")
p11 <- qplot(1:length(wind), wind, data = X, geom = "line")
p12 <- qplot(1:length(rain), rain, data = X, geom = "line")

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, nrow=3, ncol=4)
```

Plotting the data with lines doesn't always make sense, so creating a scatterplot will often time make it easier to identify relationships between variables.
```{r, fig.width= 12, fig.height=9, warning=FALSE}
p1 <- qplot(x = X$X, y = t$area, geom = "point")
p2 <- qplot(x = X$Y, y = t$area, geom = "point")
p3 <- qplot(x = X$month, y = t$area, geom = "point")
p4 <- qplot(x = X$day, y =  t$area, geom = "point")
p5 <- qplot(x = X$FFMC, y =  t$area, geom = "point")
p6 <- qplot(x = X$DMC,  y =  t$area, geom = "point")
p7 <- qplot(x = X$DC, y =  t$area, geom = "point")
p8 <- qplot(x = X$ISI, y =  t$area, geom = "point")
p9 <- qplot(x = X$temp, y =  t$area, geom = "point")
p10 <- qplot(x = X$RH, y =  t$area, geom = "point")
p11 <- qplot(x = X$wind, y =  t$area, geom = "point")
p12 <- qplot(x = X$rain, y =  t$area, geom = "point")

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, nrow=3, ncol=4)
```

Remember the histogram from earlier? The skew in the data can be a massive issue for further analysis or ML model application. To amplify the difference in the data, we'll spread them out by taking the log. The 2nd histogram demonstrates the new distribution.
Notice we added 1 to area, since you can't take the log of 0.
```{r}
ap1 <- ggplot(t, aes(x = area)) + geom_histogram(binwidth = 100)
t$logarea <- log(t$area + 1)
ap2 <- ggplot(t, aes(x = logarea)) + geom_histogram(binwidth = 1)
grid.arrange(ap1, ap2, nrow = 1)
```

We'll the plot create the scatter plots again to gain a better understanding of the correlation between variables.
```{r}
p1 <- qplot(x = X$X, y =  t$logarea, geom = "point")
p2 <- qplot(x = X$Y, y =  t$logarea, geom = "point")
p3 <- qplot(x = X$month, y =  t$logarea, geom = "point")
p4 <- qplot(x = X$day, y =  t$logarea, geom = "point")
p5 <- qplot(x = X$FFMC, y =  t$logarea, geom = "point")
p6 <- qplot(x = X$DMC,  y =  t$logarea, geom = "point")
p7 <- qplot(x = X$DC, y =  t$logarea, geom = "point")
p8 <- qplot(x = X$ISI, y =  t$logarea, geom = "point")
p9 <- qplot(x = X$temp, y =  t$logarea, geom = "point")
p10 <- qplot(x = X$RH, y =  t$logarea, geom = "point")
p11 <- qplot(x = X$wind, y =  t$logarea, geom = "point")
p12 <- qplot(x = X$rain, y =  t$logarea, geom = "point")

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, nrow=3, ncol=4)
```

## Practice Using the Auto MPG dataset

Here we'll be performing some of the same operations done above. Afterwards, to emulate Streamlit's ability to build interactive tools / dashboards, we'll create our first R Shiny app! (My first at least).
```{r, warning=FALSE}
columns <- c('mpg', 'cylinders', 'displacement', 'horsepower', 'weight',
             'acceleration', 'model year', 'origin', 'car name')
auto_mpg <- read_table("auto-mpg.data-original", 
    col_names = columns)
head(auto_mpg)
length(which(is.na(auto_mpg)))
auto_mpg <- drop_na(auto_mpg)
dim(auto_mpg)
length(which(is.na(auto_mpg)))
```

In the following app, we'll used sliders and selection tools to filter data for description and visualization. The code to create it is below with a few comments to serve as guidance!

<iframe height="800" width="100%" frameborder="no" src="https://samuellouissaint.shinyapps.io/forest_fires/"> </iframe>

In addition, here's very helpful R Shiny's documentation for how to [deploy](https://shiny.rstudio.com/deploy/) an app to the web along with a [blog post](https://statsandr.com/blog/how-to-embed-a-shiny-app-in-blogdown/) for how to embed your Shiny apps into a blogdown site. Just load packages that you need within the app before you deploy it!

```{r, eval = FALSE}
# Define UI for application.
ui <- fluidPage(

    # Application title
    titlePanel("Forest Fires Data"),

    # Sidebar with a slider and select inputs.
    sidebarLayout(
        sidebarPanel(
            helpText('Forest fire Data Filtered by Burned Area.'),
            selectInput(
        "sum", "Show / Hide Data Summary",
        c(Show = "show",
          "Hide" = "notshow")),
            sliderInput("range",
                        "Choose a minimum and maximum area:",
                        min = min(ff_data_num$area),
                        max = max(ff_data_num$area),
                        value = c(0,30), sep = '')
        ),

        # Show table outputs and plot output
        mainPanel(
           shiny::verbatimTextOutput('temp'),
      conditionalPanel(
        condition = "input.sum == 'show'",
        tableOutput('Summary')),
        tableOutput("DataTable"),
        plotOutput("Plots")
      ) ) )

# 

# Define server logic required to create desired outputs
server <- function(input, output, session) {

    output$Summary <- renderTable({
        sumdt <- as.data.frame(do.call(cbind, lapply(ff_data_num, summary)))
        sumdt[4,] <- round(sumdt[4,], digits = 4) 
        sumdt <- sumdt%>%
  add_column('Metric' = c('Min', 'Q1', 'Median', 'Mean', 'Q3', 'Max')) %>%
          mutate
sumdt[,c(14,1:13)] })
    
    output$DataTable <- renderTable({
        dt <- ff_data_num[ff_data_num$area >= input$range[1] & ff_data_num$area <= input$range[2],]
        dt })
    
    output$Plots <- renderPlot({
      dt <- ff_data_num[ff_data_num$area >= input$range[1] & ff_data_num$area <= input$range[2],]
      plot1 <- ggplot(data = dt) +
        geom_point(aes(X, Y))
      plot2 <- ggplot(data = dt) +
        geom_histogram(aes(area))
      plot3 <- ggplot(data = dt) +
        geom_point(aes(temp, area))
      plot4 <- ggplot(data = dt) +
        geom_point(aes(wind, area))
      grid.arrange(plot1, plot2, plot3, plot4, nrow = 2, ncol = 2,
                   top = textGrob(paste("The number of filtered data samples:", dim(dt)[1])))
    }) }

# Run the application 
shinyApp(ui = ui, server = server)
```